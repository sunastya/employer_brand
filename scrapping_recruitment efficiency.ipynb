{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvkotXD1FsOb",
        "outputId": "cb89f11b-c64a-4e73-a86f-4a6d41fb7be0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Страницы поиска собраны\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "\n",
        " \n",
        "def getPage(page = 0, company = ''):\n",
        "\n",
        "    # We create a method for getting a page with a list of vacancies.\n",
        "    # Arguments:\n",
        "    #   search field - filter for seraching, i.e. search by company name\n",
        "    #   text - search request, in our case name of the company\n",
        "    #   page - Page index, starts from 0. Default value is 0, i.e. first page\n",
        "    #   per_page - number of vacancies per page. we will ask for ni more than 20 pages with 100 vacancies each\n",
        "    #   professional role - filter to get only IT vacancies\n",
        "\n",
        "    \n",
        "    # Reference for GET request parameters\n",
        "    params = {\n",
        "        'search_field': 'company_name',\n",
        "        'text': company,\n",
        "        'page': page, \n",
        "        'per_page': 100,\n",
        "        'professional_role': [156, 160, 10, 12, 150, 25, 165, 34, 36, 73, 155, 96, 164, 104, 157, 107, 112, 113, 148, 114, 116, 121, 124, 125, 126]\n",
        "    }\n",
        "    \n",
        "    \n",
        "    req = requests.get('https://api.hh.ru/vacancies', params) # Sending a request to the API\n",
        "    data = req.content.decode() # Decoding the response so that the Cyrillic alphabet is displayed correctly\n",
        "    req.close()\n",
        "    return data\n",
        "\n",
        "\n",
        "# Specify the names of companies to search\n",
        "\n",
        "companies = ['positive technologies', 'aviasales.ru', 'ozon',\n",
        "              'headhunter', 'selectel', 'redmadrobot', 'лаборатория касперского', '2гис', 'додо', 'dodo', 'яндекс', 'huawei', 'райффайзен',\n",
        "              'nexign', 'avito', 'playrix', 'точка', 'vk', 'ibs', 'инфосистемы джет', 'тинькофф', 'контур', 'газинформсервис', 'альфа-банк',\n",
        "              'skyeng', 'северсталь', 'московская биржа', 'газпром нефть', 'леруа мерлен', 'x5', 'росатом', 'сибур', 'нлмк',\n",
        "              'газпром автоматизация', 'крок', 'центр финансовых технологий', 'сбер', 'softline', 'иннотех', 'гринатом', 'мтс', 'lamoda', 'icl', 'ланит', 'рт лабс', 'лига цифровой экономики',\n",
        "              'газпромбанк', 'tele2', 'ай-теко', 'м.видео-эльдорадо', 'сбермаркет', 'ростех', 'сбермегамаркет', 'тензор', 'мегафон', 'bell integrator', 'втб', 'барс груп',\n",
        "              'росбанк', '1с', 'открытие', 'мтс банк', 'билайн', 'сибинтек', 'отр', 'лента', '1с-рарус', 'rarus', '36.6', 'центральный банк российской федерации', 'ростелеком-солар', 'эр-телеком', 'первый бит', 'ржд технологии',\n",
        "              'ростелеком', 'магнит', 'wildberries', 'почта россии', 'почта банк', 'dataart', 'accenture',\n",
        "              'haulmont', 'деловые решения и технологии', 'epam', 'okko', 'naumen'\n",
        "             ]\n",
        "\n",
        "# Read the first 2000 vacancies\n",
        "for company in companies:\n",
        "  for page in range(0, 20):\n",
        "      \n",
        "      # Converting Request Response Text to a Python Reference\n",
        "      jsObj = json.loads(getPage(page, company))\n",
        "      \n",
        "      # Save the files to the folder {path to the current document with the script}\\docs\\pagination\n",
        "      # Determine the number of files in the folder to save the document with the response to the request\n",
        "      # The resulting value is used to form the name of the document\n",
        "      nextFileName = './docs/pagination/{}.json'.format(len(os.listdir('./docs/pagination')))\n",
        "      \n",
        "      # We create a new document, write the request response into it, then close\n",
        "      f = open(nextFileName, mode='w', encoding='utf8')\n",
        "      f.write(json.dumps(jsObj, ensure_ascii=False))\n",
        "      f.close()\n",
        "      \n",
        "      # Checking to the last page if there are less than 2000 vacancies\n",
        "      if (jsObj['pages'] - page) <= 1:\n",
        "          break\n",
        "      \n",
        "      # An optional delay, but in order not to load hh.ru services, we will leave it. 5 sec we can wait\n",
        "      time.sleep(1)\n",
        "    \n",
        "print('Search pages collected')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Yw6xdVHoxg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# We get a list of previously created files with a list of vacancies and go through it in a loop \n",
        "page_num = 0\n",
        "for fl in os.listdir('./docs/pagination'):\n",
        "    vac_num = 0\n",
        "    # Open a file, read its contents, close the file\n",
        "    f = open('./docs/pagination/{}'.format(fl), encoding='utf8')\n",
        "    jsonText = f.read()\n",
        "    f.close()\n",
        "    \n",
        "    # Let's convert the received text into a dictionary object\n",
        "    jsonObj = json.loads(jsonText)\n",
        "    if 'items' in jsonObj:\n",
        "      # We receive and go through the list of vacancies directly\n",
        "\n",
        "      for v in jsonObj['items']:\n",
        "          # We turn to the API and get detailed information on a specific vacancy\n",
        "          print(page_num, vac_num, v['url'])\n",
        "          req = requests.get(v['url'])\n",
        "          data = req.content.decode()\n",
        "          req.close()\n",
        "          \n",
        "          # Create a json file with vacancy ID as title\n",
        "          # We write the request response into it and close the file\n",
        "          fileName = './docs/vacancies/{}.json'.format(v['id'])\n",
        "          f = open(fileName, mode='w', encoding='utf8')\n",
        "          f.write(data)\n",
        "          f.close()\n",
        "          \n",
        "          time.sleep(0.25)\n",
        "          vac_num += 1\n",
        "      page_num += 1\n",
        "print('Vacancies collected')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0b1wJAmH7sZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "92c5df20-5b85-4052-d14d-8dba88434103"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Вакансии загружены в БД'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from sqlalchemy import engine as sql\n",
        "from IPython import display\n",
        "\n",
        "# Creating lists for the columns of the vacancies table\n",
        "IDs = [] # List of Job IDs\n",
        "company = [] # Company name\n",
        "names = [] # List of job titles\n",
        "descriptions = [] # List of job descriptions\n",
        "viewers = [] # Number of views\n",
        "publication = [] # Date of publication\n",
        "creation = [] # Date when the application for the vacancy was opened\n",
        "prof = [] # Specialization\n",
        "url = [] # Vacancy URL\n",
        "\n",
        "\n",
        "# The output will display the progress\n",
        "# To do this, we find out the total number of files that need to be processed.\n",
        "# Set the counter of processed files to zero\n",
        "cnt_docs = len(os.listdir('./docs/vacancies'))\n",
        "i = 0\n",
        "\n",
        "# We go through all the files in the vacancies folder\n",
        "for fl in os.listdir('./docs/vacancies'):\n",
        "    \n",
        "    # Open, read and close a file\n",
        "    f = open('./docs/vacancies/{}'.format(fl), encoding='utf8')\n",
        "    jsonText = f.read()\n",
        "    f.close()\n",
        "    \n",
        "    # We translate the text of the file into a directory\n",
        "    jsonObj = json.loads(jsonText)\n",
        "    \n",
        "    # Filling out lists for tables\n",
        "    IDs.append(jsonObj['id'])\n",
        "    company.append(jsonObj['employer'])\n",
        "    names.append(jsonObj['name'])\n",
        "    descriptions.append(jsonObj['description'])\n",
        "    publication.append(jsonObj['published_at'])\n",
        "    creation.append(jsonObj['initial_created_at'])\n",
        "    prof.append(jsonObj['professional_roles'])\n",
        "    url.append(jsonObj['alternate_url'])\n",
        "    \n",
        "    # We increase the counter of processed files by 1, clear the output of the cell and display the progress\n",
        "    i += 1\n",
        "    display.clear_output(wait=True)\n",
        "    display.display('Готово {} из {}'.format(i, cnt_docs))\n",
        "\n",
        "\n",
        "# We create a pandas dataframe in which we save all the information\n",
        "df = pd.DataFrame({'id': IDs, 'employer': company, 'name': names, 'description': descriptions, \n",
        "                   'published_at': publication, 'initial_created_at': creation, 'professional_roles': prof, 'alternate_url': url })\n",
        "\n",
        "\n",
        "# Display a message about the end of the program\n",
        "display.clear_output(wait=True)\n",
        "display.display('Vacancies uploaded to dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AxNWhyu4p3v"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "# We create functions so that dates from the dataset are displayed in the correct format, convenient for further analysis\n",
        "def date_modify(d):\n",
        "  d1 = datetime.datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S%z\")\n",
        "  new_format = \"%d.%m.%Y\"\n",
        "  return d1.strftime(new_format)\n",
        "\n",
        "def time_modify(d):\n",
        "  d1 = datetime.datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S%z\")\n",
        "  new_format = \"%H:%M\"\n",
        "  return d1.strftime(new_format)\n",
        "  \n",
        "def date_and_time(d):\n",
        "  d1 = datetime.datetime.strptime(d, \"%Y-%m-%dT%H:%M:%S%z\")\n",
        "  new_format = \"%d.%m.%Y %H:%M:%S\"\n",
        "  return d1.strftime(new_format)\n",
        "\n",
        "\n",
        "df['role_id'] = df.professional_roles.apply(lambda s: s[0]['id'])\n",
        "df['company_name'] = df.employer.apply(lambda s: s['name'])\n",
        "\n",
        "df['published_date'] = df.published_at.apply(date_modify)\n",
        "df['published_time'] = df.published_at.apply(time_modify)\n",
        "df['published_DT'] = df.published_at.apply(date_and_time)\n",
        "\n",
        "df['initial_date'] = df.initial_created_at.apply(date_modify)\n",
        "df['initial_time'] = df.initial_created_at.apply(time_modify)\n",
        "df['initial_DT'] = df.initial_created_at.apply(date_and_time)\n",
        "\n",
        "df['parse_date'] = pd.Timestamp.today().strftime(\"%d.%m.%Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fMKRCkSw5YC"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7R5E4RuxNHc"
      },
      "outputs": [],
      "source": [
        "df.to_csv('file.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EZ6QIziyR5T"
      },
      "outputs": [],
      "source": [
        "df.to_excel('file_excel.xlsx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}